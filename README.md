# DocIA - Sistema de Busca Inteligente de Documentos üß†üìö

Sistema avan√ßado de busca e an√°lise de documentos com IA, oferecendo respostas em linguagem natural baseadas no conte√∫do dos seus arquivos.

## üöÄ Caracter√≠sticas Principais

- **Busca Sem√¢ntica Inteligente**: Encontra informa√ß√µes mesmo sem correspond√™ncia exata de palavras
- **Respostas em Linguagem Natural**: IA gera respostas diretas e contextualizadas
- **M√∫ltiplos Formatos**: Suporte para PDF, DOCX e TXT
- **Interface Web Moderna**: Interface limpa e responsiva
- **Monitoramento Autom√°tico**: Detecta altera√ß√µes nos documentos automaticamente
- **IA Local**: Usa Ollama com modelo Mistral para m√°xima privacidade

## üìã Pr√©-requisitos

- **Python 3.8+**
- **Para execu√ß√£o local**: Ollama + modelo Mistral (recomendado)
- **Para execu√ß√£o com Docker**: Docker e Docker Compose

## üîß Instala√ß√µes

### Op√ß√£o 1: Execu√ß√£o Local (Recomendada)

1. **Instale o Ollama:**
   - Baixe de: <https://ollama.com/download>
   - Execute o instalador
   - Reinicie o terminal

2. **Baixe o modelo Mistral:**

   ```bash
   ollama pull mistral
   ```

3. **Clone e configure o projeto:**

   ```bash
   git clone [seu-repositorio]
   cd docIA
   python -m venv .venv
   
   # Windows
   .venv\Scripts\activate
   
   # Linux/Mac
   source .venv/bin/activate
   
   pip install -r requirements.txt
   ```

4. **Execute:**

   ```bash
   python smart_app.py
   ```

### Op√ß√£o 2: Execu√ß√£o com Kubernetes (Produ√ß√£o)

1. **Deploy no Kubernetes:**

   ```bash
   # Windows
   deploy-k8s.bat
   
   # Linux/Mac
   ./deploy-k8s.sh
   ```

   O script automaticamente:
   - Constr√≥i a imagem Docker
   - Cria namespace e recursos do K8s
   - Configura volumes persistentes
   - Exp√µe a aplica√ß√£o na porta 30500

2. **Acesse**: <http://localhost:30500>

### Op√ß√£o 3: Execu√ß√£o com Docker Compose

1. **Execute com Docker Compose:**

   ```bash
   docker-compose up --build
   ```

   O Docker automaticamente:
   - Instala o Ollama
   - Baixa o modelo Mistral
   - Configura tudo para funcionar

## üìù Como Usar

1. **Adicione seus documentos** na pasta `documents/`
2. **Acesse**: <http://localhost:5000>
3. **Fa√ßa perguntas** sobre o conte√∫do dos documentos
4. **Reindexe** quando adicionar novos arquivos (ou aguarde a detec√ß√£o autom√°tica)

### Exemplos de Perguntas

- "Quais foram as principais decis√µes da √∫ltima reuni√£o?"
- "H√° alguma men√ß√£o sobre or√ßamento?"
- "Quem foram os participantes da reuni√£o de mar√ßo?"
- "Resumo dos pontos discutidos sobre marketing"

## üß† Modelos de IA

O sistema prioriza sempre o **modelo Mistral via Ollama** para m√°xima qualidade e privacidade:

1. **üéØ Mistral (Padr√£o)**: Modelo local de alta qualidade
2. **‚ö†Ô∏è Sistema Interno**: Fallback se Ollama n√£o estiver dispon√≠vel

### Configura√ß√£o do Modelo

O sistema est√° configurado para usar sempre o **Mistral** como padr√£o:

- **Localmente**: Detecta automaticamente se Mistral est√° dispon√≠vel
- **Docker**: Automaticamente baixa e configura o Mistral
- **Vari√°vel de ambiente**: `OLLAMA_MODEL=mistral` (j√° configurado)

## üìä Status do Sistema

A interface mostra:

- ‚úÖ **Ollama - mistral**: Funcionando perfeitamente
- ‚ö†Ô∏è **Sistema Interno**: Funcional, mas qualidade limitada

## üîß Configura√ß√µes Avan√ßadas

### Vari√°veis de Ambiente

```bash
OLLAMA_MODEL=mistral          # For√ßa uso do Mistral
FLASK_ENV=production          # Modo de produ√ß√£o
TRANSFORMERS_CACHE=/app/.cache # Cache dos modelos
```

### Personaliza√ß√£o

- **Tamanho dos chunks**: Modifique `chunk_size` em `smart_indexer.py`
- **N√∫mero de resultados**: Ajuste `max_results` nas buscas
- **Threshold de similaridade**: Configure em `_semantic_search`

## ‚ò∏Ô∏è Kubernetes - Enterprise Edition

### Deploy R√°pido com Makefile

```bash
# Ver todos os comandos dispon√≠veis
make help

# Build e deploy completo
make build && make deploy

# Deploy r√°pido (sem build)
make quick-deploy

# Verificar status
make status

# Ver logs
make logs
```

### Deploy Manual

#### Windows

```bash
# Setup do cluster (se necess√°rio)
setup-remote-k8s.bat

# Deploy completo com interface interativa
deploy\deploy.bat
```

#### Linux/Mac

```bash
# Setup do cluster (se necess√°rio)
chmod +x setup-remote.sh && ./setup-remote.sh

# Deploy completo com interface interativa
chmod +x deploy/deploy.sh && ./deploy/deploy.sh
```

### Recursos Enterprise

#### Seguran√ßa

- **RBAC**: Service accounts com permissions m√≠nimas
- **Security Context**: Execu√ß√£o n√£o-root
- **Network Policies**: Isolamento de rede
- **Secrets**: Gerenciamento seguro de credenciais

#### Observabilidade

- **Health Checks**: Liveness, Readiness e Startup probes
- **Metrics**: Prometheus integration
- **Logging**: Structured logs com forwarding
- **Monitoring**: Grafana dashboards

#### Escalabilidade

- **HPA**: Auto-scaling baseado em CPU/mem√≥ria
- **Resource Management**: Limits e requests configurados
- **Rolling Updates**: Zero-downtime deployments
- **Multiple Environments**: Dev, Staging, Produ√ß√£o

### Configura√ß√µes por Ambiente

| Ambiente | Replicas | CPU Request | Memory Request | Storage Class |
|----------|----------|-------------|----------------|---------------|
| Development | 1 | 500m | 1Gi | standard |
| Staging | 2 | 1000m | 2Gi | fast-ssd |
| Production | 3 | 2000m | 4Gi | fast-ssd |

### Recursos Provisionados

- **Namespace**: doc-ia com labels padronizadas
- **Deployment**: Multi-replica com rolling updates
- **Services**: ClusterIP, NodePort e Headless
- **PVCs**: Documentos (20Gi), Cache (10Gi), Logs (5Gi)
- **Ingress**: nginx com SSL/TLS e rate limiting
- **ConfigMap**: Configura√ß√£o estruturada
- **Secrets**: Credenciais criptografadas
- **RBAC**: Service accounts com permissions m√≠nimas
- **HPA**: Auto-scaling configurado
- **Network Policies**: Seguran√ßa de rede
- **Monitoring**: ServiceMonitor e dashboards

### Comandos de Gerenciamento

```bash
# Escalabilidade
make scale REPLICAS=5

# Atualiza√ß√£o
make update

# Backup
make backup

# Restaura√ß√£o
make restore BACKUP_FILE=backup/file.yaml

# Debug
make debug

# Limpeza
make clean

# Deletar tudo
make delete
```

### Monitoramento

```bash
# Health check completo
make health

# Monitorar recursos
make monitor

# Ver eventos
make events

# Testar conectividade
make test
```

### Troubleshooting

```bash
# Logs detalhados
make logs-tail

# Conectar ao pod
make dev-shell

# Descrever deployment
make describe

# Testar rede
make network-test
```

## üê≥ Detalhes do Docker

O `Dockerfile.smart` inclui:

- Instala√ß√£o autom√°tica do Ollama
- Download do modelo Mistral
- Configura√ß√£o de cache otimizada
- Inicializa√ß√£o autom√°tica dos servi√ßos

## üìÅ Estrutura do Projeto

```
docIA/
‚îú‚îÄ‚îÄ smart_app.py           # Aplica√ß√£o Flask principal
‚îú‚îÄ‚îÄ smart_indexer.py       # Motor de busca e IA
‚îú‚îÄ‚îÄ documents/             # Pasta dos documentos
‚îú‚îÄ‚îÄ Dockerfile.smart       # Container com Ollama+Mistral
‚îú‚îÄ‚îÄ docker-compose.yml     # Orquestra√ß√£o Docker
‚îú‚îÄ‚îÄ k8s-*.yaml            # Manifests do Kubernetes
‚îú‚îÄ‚îÄ deploy-k8s.sh         # Script de deploy K8s (Linux/Mac)
‚îú‚îÄ‚îÄ deploy-k8s.bat        # Script de deploy K8s (Windows)
‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias Python
‚îî‚îÄ‚îÄ README.md             # Este arquivo
```

## üöÄ Performance

- **Indexa√ß√£o**: ~100 documentos/minuto
- **Busca**: <1 segundo por consulta
- **Mem√≥ria**: ~200MB base + modelo IA
- **CPU**: Otimizado para uso eficiente

## üîí Privacidade

- **100% Local**: Nenhum dado sai da sua m√°quina
- **Sem APIs externas**: Modelo IA roda localmente
- **Controle total**: Voc√™ possui todos os dados

## üõ†Ô∏è Troubleshooting

### Problema: "Sistema Interno" em vez de Mistral

**Solu√ß√£o:**

1. Verifique se Ollama est√° rodando: `ollama list`
2. Instale o Mistral: `ollama pull mistral`
3. Reinicie a aplica√ß√£o

### Problema: Baixa qualidade nas respostas

**Solu√ß√£o:**

1. Instale o Ollama + Mistral (modelo mais poderoso)
2. Adicione mais documentos relevantes
3. Reformule a pergunta de forma mais espec√≠fica

### Problema: Documentos n√£o indexados

**Solu√ß√£o:**

1. Verifique se est√£o na pasta `documents/`
2. Clique em "Reindexar" na interface
3. Verifique os logs no terminal

## üìä Vers√£o Atual

**v2.3.0** - Enterprise Kubernetes Edition

- **üîí Seguran√ßa Enterprise**: RBAC, Security Context, Network Policies, Secrets Management
- **üìä Observabilidade**: Health checks avan√ßados, Prometheus metrics, Grafana dashboards
- **‚ö° Escalabilidade**: HPA com auto-scaling, Resource management otimizado
- **üîÑ Rolling Updates**: Zero-downtime deployments com m√∫ltiplos ambientes
- **üíæ Storage Avan√ßado**: Volumes persistentes com backup strategy configurado
- **üõ†Ô∏è DevOps Ready**: Makefile com 25+ comandos, Scripts de deploy interativos
- **üåê Multi-Ambiente**: Configura√ß√µes espec√≠ficas para Dev, Staging e Produ√ß√£o
- **üîç Monitoring**: ServiceMonitor, Log forwarding, Network policies de seguran√ßa

### Funcionalidades Enterprise Adicionadas

- ‚úÖ RBAC com service accounts seguros
- ‚úÖ Security contexts n√£o-root
- ‚úÖ Network policies para isolamento
- ‚úÖ Secrets para dados sens√≠veis
- ‚úÖ HPA com auto-scaling inteligente
- ‚úÖ Health checks robustos (liveness, readiness, startup)
- ‚úÖ Prometheus + Grafana integration
- ‚úÖ Volumes com backup automatizado
- ‚úÖ Scripts de deploy interativos (Windows/Linux)
- ‚úÖ Makefile com comandos de gerenciamento
- ‚úÖ Configura√ß√µes por ambiente (dev/staging/prod)
- ‚úÖ TLS/SSL com cert-manager
- ‚úÖ Rate limiting no Ingress

---

**üí° Dica**: Para melhor experi√™ncia, use sempre o Ollama + Mistral. O sistema funciona sem ele, mas a qualidade das respostas √© significativamente superior com IA local!
